{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Explanation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Importing necessary libraries:**\n",
    "   - The code starts by importing the required libraries/modules such as `io`, `random`, `string`, `warnings`, `numpy`, `nltk`, and specific modules from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import io\n",
    "import random\n",
    "import string  # To process standard python strings\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Downloading NLTK packages:**\n",
    "   - The code downloads popular NLTK packages needed for text processing. It checks for the presence of the packages and downloads them if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('popular', quiet=True)  # For downloading packages\n",
    "\n",
    "# Uncomment the following only the first time\n",
    "#nltk.download('punkt')  # First-time use only\n",
    "#nltk.download('wordnet')  # First-time use only"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Reading the corpus:**\n",
    "   - The code opens a file named \"chatbot.txt\" and reads its content into the `raw` variable. The corpus is converted to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the corpus\n",
    "with open('C:\\\\Users\\\\Larissa Lorenzi\\\\Documents\\\\chatbot.txt','r', encoding='utf8', errors ='ignore') as fin:\n",
    "    raw = fin.read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Tokenization:**\n",
    "   - The corpus is tokenized into sentences using `nltk.sent_tokenize()`, and the result is stored in the `sent_tokens` list.\n",
    "   - The corpus is also tokenized into words using `nltk.word_tokenize()`, and the result is stored in the `word_tokens` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "sent_tokens = nltk.sent_tokenize(raw)  # Converts the corpus into a list of sentences\n",
    "word_tokens = nltk.word_tokenize(raw)  # Converts the corpus into a list of words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Preprocessing:**\n",
    "   - The code defines a function called `LemTokens()` that lemmatizes the given tokens using `WordNetLemmatizer`.\n",
    "   - A dictionary `remove_punct_dict` is created to remove punctuation from text.\n",
    "   - Another function called `LemNormalize()` is defined, which normalizes the text by converting it to lowercase, removing punctuation, and lemmatizing the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "lemmer = WordNetLemmatizer()\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    '''Lemmatizes tokens'''\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    '''Normalizes and lemmatizes text'''\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Keyword Matching:**\n",
    "   - The code defines two tuples: `GREETING_INPUTS` containing various greeting phrases and `GREETING_RESPONSES` containing corresponding responses.\n",
    "   - The function `greeting()` checks if the user's input matches any greeting phrase and returns a randomly selected response from `GREETING_RESPONSES`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword Matching\n",
    "GREETING_INPUTS = ('hello', 'hi', 'greetings', 'sup', \"what's up\", 'hey')\n",
    "GREETING_RESPONSES = ['Hi!', 'Hey!', '*nods*', 'Hi, there!', 'Hello!', 'I am glad! You are talking to me.']\n",
    "\n",
    "def greeting(sentence):\n",
    "    \"\"\"If the user's input is a greeting, return a greeting response.\"\"\"\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **Generating response:**\n",
    "   - The function `response()` generates a response to the user's input based on the TF-IDF (Term Frequency-Inverse Document Frequency) approach.\n",
    "   - The user's input is appended to `sent_tokens` to include it in the corpus for generating appropriate responses.\n",
    "   - TF-IDF vectorization is applied using `TfidfVectorizer` to convert the corpus into a numerical representation.\n",
    "   - Cosine similarity is calculated between the user's input (vectorized) and all other sentences in the corpus using `cosine_similarity`.\n",
    "   - The most similar sentence is identified based on the cosine similarity scores, and its index is stored in `idx`.\n",
    "   - The response is constructed by retrieving the most similar sentence from `sent_tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating response\n",
    "def response(user_response):\n",
    "    \"\"\"Generates a response to the user's input\"\"\"\n",
    "    robot_response = ''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)  # Applies TF-IDF vectorization to the sentences\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)  # Computes cosine similarity between user's input and corpus sentences\n",
    "    idx = vals.argsort()[0][-2]  # Retrieves the index of the most similar sentence\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]  # Retrieves the cosine similarity score of the most similar sentence\n",
    "    if req_tfidf == 0:\n",
    "        robot_response = robot_response + \"I am sorry! I don't understand you\"\n",
    "        return robot_response\n",
    "    else:\n",
    "        robot_response = robot_response + sent_tokens[idx]  # Retrieves the most similar sentence as the response\n",
    "        return robot_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **Main conversation loop:**\n",
    "   - A flag `flag` is set to `True` to indicate the start of the conversation.\n",
    "   - The program displays an introductory message.\n",
    "   - Inside a while loop, it prompts the user for input using `input()`.\n",
    "   - The user's input is converted to lowercase.\n",
    "   - If the user doesn't input \"bye,\" it checks for expressions of gratitude. If found, it exits the loop with a response.\n",
    "   - If the user's input is a greeting, it responds with a randomly selected greeting from `GREETING_RESPONSES`.\n",
    "   - Otherwise, it generates a response using the `response()` function and removes the user's input from `sent_tokens`.\n",
    "   - If the user inputs \"bye,\" it exits the loop and says goodbye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBOT: My name is Robot. I will answer your queries about Chatbots. If you want to exit, type Bye!\n",
      "ROBOT: Hi!\n",
      "ROBOT: In order to speed up this process, designers can use dedicated chatbot design tools, that allow for immediate preview, team collaboration and video export.An important part of the chatbot design is also centered around user testing.\n",
      "ROBOT: Design\n",
      "The chatbot design is the process that defines the interaction between the user and the chatbot.The chatbot designer will define the chatbot personality, the questions that will be asked to the users, and the overall interaction.It can be viewed as a subset of the conversational design.\n",
      "ROBOT: Bye! Take care...\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "print('ROBOT: My name is Robot. I will answer your queries about Chatbots. If you want to exit, type Bye!')\n",
    "while flag:\n",
    "    user_response = input()\n",
    "    user_response = user_response.lower()\n",
    "    if user_response != 'bye':\n",
    "        if user_response == 'thanks' or user_response == 'thank you':\n",
    "            flag = False\n",
    "            print('ROBOT: You are welcome.')\n",
    "        else:\n",
    "            if greeting(user_response) is not None:\n",
    "                print('ROBOT: ' + greeting(user_response))  # Responds with a greeting if the user's input is a greeting\n",
    "            else:\n",
    "                print('ROBOT: ', end=\"\")\n",
    "                print(response(user_response))  # Generates and prints a response based on user's input\n",
    "                sent_tokens.remove(user_response)  # Removes the user's input from the list of sentences for future comparisons\n",
    "    else:\n",
    "        flag = False\n",
    "        print('ROBOT: Bye! Take care...')  # Says goodbye and exits the conversation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
